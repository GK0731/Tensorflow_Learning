{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "\n",
    "So, imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
    "\n",
    "How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
    "\n",
    "Hint: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units = 1, input_shape = [1] )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "x = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], dtype=float)\n",
    "y = np.array([100, 150, 200, 250, 300, 350], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples\n",
      "Epoch 1/25\n",
      "6/6 [==============================] - 0s 27ms/sample - loss: 45.3878\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 21.0082\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 9.7246\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 4.5022\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 2.0851\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 0.9664\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 0.4486\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 0.2090\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 0.0980\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 0.0467\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0229\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0119\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0068\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0044\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0033\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0028\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0025\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0024\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 3ms/sample - loss: 0.0023\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0023\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0023\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 0s/sample - loss: 0.0023\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 3ms/sample - loss: 0.0022\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 0.0022\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 417us/sample - loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15843388>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y/100, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.066872]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([7.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "Some notes:\n",
    "1. It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
    "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "\n",
    "I've started the code for you below -- how would you finish it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "y_train = y_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),                                    \n",
    "                                    tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(768, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(1280, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallBack(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc') > 0.99):\n",
    "            print(\"Reached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callBacks = MyCallBack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 47s 784us/sample - loss: 0.0024 - acc: 0.0987\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 48s 802us/sample - loss: 0.0000e+00 - acc: 0.0987 - loss: 0.0000e+00 - acc: \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 47s 781us/sample - loss: 0.0000e+00 - acc: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 45s 751us/sample - loss: 0.0000e+00 - acc: 0.0987\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 45s 752us/sample - loss: 0.0000e+00 - acc: 0.0987\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 48s 798us/sample - loss: 0.0000e+00 - acc: 0.0987 - los\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 49s 816us/sample - loss: 0.0000e+00 - acc: 0.0987\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 47s 776us/sample - loss: 0.0000e+00 - acc: 0.0987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 49s 818us/sample - loss: 0.0000e+00 - acc: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 49s 817us/sample - loss: 0.0000e+00 - acc: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c49f88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10, callbacks= [callBacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 181us/sample - loss: 0.0027 - acc: 0.0987\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 2.3485e-07 - acc: 0.0987\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 182us/sample - loss: 5.2816e-08 - acc: 0.0987\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 198us/sample - loss: 1.6937e-08 - acc: 0.0987\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 12s 192us/sample - loss: 6.5982e-09 - acc: 0.0987\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 11s 184us/sample - loss: 2.8451e-09 - acc: 0.0987\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 1.2934e-09 - acc: 0.0987\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 159us/sample - loss: 6.6558e-10 - acc: 0.0987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 158us/sample - loss: 3.4769e-10 - acc: 0.0987\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 172us/sample - loss: 2.2054e-10 - acc: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15ce8f48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train/255.0\n",
    "y_train = y_train/255.0\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc') > 0.99):\n",
    "            print(\"Reached 99% accuracy so cancelling trining!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "                                   ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 10, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_nerual_network():\n",
    "#     model = tf.keras.models.Sequential()\n",
    "\n",
    "#     model.add(tf.keras.layers.Flatten())\n",
    "#     model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # Simple Dense Layer\n",
    "#     model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # Simple Dense Layer\n",
    "#     model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))   # Output layer\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# train_images, train_labels = load_dataset() #this function works fine\n",
    "# model = create_nerual_network()\n",
    "\n",
    "# model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.fit(train_images, train_labels, epochs = 15, verbose=2)\n",
    "# train_loss, train_acc = model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your exercise see if you can improve MNIST to 99.8% accuracy or more using only a single convolutional layer and a single MaxPooling 2D. You should stop training once the accuracy goes above this amount. It should happen in less than 20 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your layers.\n",
    "\n",
    "``````````````````````````````````````````````````````````````````````````````````````````````````````\n",
    "\n",
    "When 99.8% accuracy has been hit, you should print out the string \"Reached 99.8% accuracy so cancelling training!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (28, 28, 1) ),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')     \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallBack(tf.keras.callbacks.Callback):\n",
    "    def on_Epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc') > 0.998):\n",
    "            print(\"Reached accuracy 99.8 accuracy so cancelling trainning! \")\n",
    "            self.model.stop_trainning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callBacks = MyCallBack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 69s 1ms/sample - loss: 0.1381 - acc: 0.9590\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 69s 1ms/sample - loss: 0.0471 - acc: 0.9856\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0291 - acc: 0.9909\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0188 - acc: 0.9939\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0132 - acc: 0.9958\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0042 - acc: 0.9985\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0040 - acc: 0.9986\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0031 - acc: 0.9989\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 69s 1ms/sample - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 69s 1ms/sample - loss: 0.0032 - acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5694808>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 15, callbacks = [callBacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.15] *",
   "language": "python",
   "name": "conda-env-tf1.15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
